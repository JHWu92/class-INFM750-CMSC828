{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "place_choices = [\n",
    "#     'place_polys_museum','place_polys_museum_convex','place_polys_museum_convex_5m','place_polys_museum_convex_10m',\n",
    "#     'place_polys_museum_convex_50m','place_polys_museum_convex_100m',\n",
    "    'place_polys_np','place_polys_np_5m','place_polys_np_10m','place_polys_np_50m','place_polys_np_100m',\n",
    "]\n",
    "bounded_tw_paths = [DATA_DIR+'sm#tw_{}#{}.csv'.format((i+1), place_choice)for i in range(2) for place_choice in place_choices ]\n",
    "bounded_fl_paths = [DATA_DIR+'sm#fl_{}#{}.csv'.format((i+1), place_choice)for i in range(3) for place_choice in place_choices ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "bounded_tw_paths = [x for x in bounded_tw_paths if os.path.isfile(x)]\n",
    "bounded_fl_paths = [x for x in bounded_fl_paths if os.path.isfile(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path_df = pd.DataFrame(bounded_fl_paths+bounded_tw_paths,columns=['path'])\n",
    "path_df['fn']=path_df.path.apply(lambda x: x.rsplit('/',1)[1].replace('.csv',''))\n",
    "path_df['sm']=path_df.fn.apply(lambda x: x.split('#')[1].split('_')[0])\n",
    "path_df['bfr']=path_df.fn.apply(lambda x: x.split('#')[2])\n",
    "path_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs_sm = {}\n",
    "for bfr_smtype, grp in path_df.groupby(['bfr','sm']):\n",
    "    df_concat = []\n",
    "    for path in grp.path.values:\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        df_concat.append(df)\n",
    "    df_concat = pd.concat(df_concat)\n",
    "    dfs_sm[bfr_smtype] = df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simplify_sm(dfs_sm):\n",
    "    from dateutil.parser import parse as date_parse\n",
    "    def get_yr_mn_dy(x):\n",
    "        dt = date_parse(x)\n",
    "        return '%s_%02d_%02d' %(dt.year, int(dt.month),int(dt.day))\n",
    "    def clean_place(x):\n",
    "        x = x.split('##')[0]\n",
    "        x = x[:-1] if x[-1].isdigit() else x\n",
    "        return x.replace(' ','_')\n",
    "    dfs_sm_simplified = {}\n",
    "    for (bfr, smtype), df_sm in dfs_sm.items():\n",
    "        ts_col = {'tw':'ts', 'fl':'date_taken'}[smtype]\n",
    "        keep_cols = {'tw':['smid','user','place','ymd','ym'],'fl':['smid','nsid', 'place', 'ymd','ym']}[smtype]\n",
    "        df = df_sm.copy()\n",
    "        df['ymd'] = df[ts_col].apply(get_yr_mn_dy)\n",
    "        df['ym'] = df.ymd.apply(lambda x:x[:-3])\n",
    "        df = df[keep_cols].copy()\n",
    "        df.columns = ['smid','user','place', 'ymd','ym']\n",
    "        df.place = df.place.apply(clean_place)\n",
    "        dfs_sm_simplified[(bfr, smtype)]=df\n",
    "    return dfs_sm_simplified\n",
    "dfs_sm_simplified = simplify_sm(dfs_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('place_polys_np_50m', 'tw'),\n",
       " ('place_polys_np_10m', 'fl'),\n",
       " ('place_polys_np', 'tw'),\n",
       " ('place_polys_np', 'fl'),\n",
       " ('place_polys_np_100m', 'fl'),\n",
       " ('place_polys_np_100m', 'tw'),\n",
       " ('place_polys_np_10m', 'tw'),\n",
       " ('place_polys_np_5m', 'tw'),\n",
       " ('place_polys_np_50m', 'fl'),\n",
       " ('place_polys_np_5m', 'fl')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_sm_simplified.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MONTHS = ['2014_01','2014_02','2014_03','2014_04','2014_05','2014_06','2014_07','2014_08','2014_09','2014_10','2014_11','2014_12',\n",
    "          '2015_01','2015_02','2015_03','2015_04','2015_05','2015_06','2015_07','2015_08','2015_09','2015_10','2015_11','2015_12',\n",
    "          '2016_01','2016_02','2016_03','2016_04','2016_05','2016_06','2016_07','2016_08']\n",
    "\n",
    "def agg_month_lvl(dfs_sm, months):\n",
    "    dfs_sm_mn_lvl = {}\n",
    "    for (bfr,smtype), df_sm in dfs_sm.items():\n",
    "        visit_col = '{}_visit'.format(smtype)\n",
    "        sm_mn_lvl = pd.DataFrame(columns=['place','ym',visit_col])\n",
    "        for place, gb in df_sm.groupby('place'):\n",
    "            place_df = gb.copy()\n",
    "            place_df = place_df.drop_duplicates(['ymd','user'])\n",
    "            mn_lvl = place_df.groupby('ym').count()['ymd']\n",
    "            min_month_idx = months.index(mn_lvl.index.min()) if smtype=='tw' else 0\n",
    "            if min_month_idx<12:\n",
    "                mn_lvl = mn_lvl.reindex(months[min_month_idx:]).fillna(0)\n",
    "                mn_lvl = mn_lvl.reset_index()\n",
    "                mn_lvl.columns = ['ym',visit_col]\n",
    "                mn_lvl['place'] = place\n",
    "                sm_mn_lvl = pd.concat([sm_mn_lvl, mn_lvl], ignore_index=True)\n",
    "#                 print mn_lvl.head()\n",
    "        dfs_sm_mn_lvl[(bfr,smtype)] = sm_mn_lvl\n",
    "    return dfs_sm_mn_lvl\n",
    "\n",
    "dfs_sm_mn_lvl = agg_month_lvl(dfs_sm_simplified,MONTHS)\n",
    "\n",
    "def output_mn_lvl(dfs_sm_mn_lvl):\n",
    "    for (bfr,smtype), df_sm_mn_lvl in dfs_sm_mn_lvl.items():\n",
    "        df_sm_mn_lvl.to_csv('../data/mn_lvl_sm#{}#{}.csv'.format(smtype, bfr))\n",
    "output_mn_lvl(dfs_sm_mn_lvl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bounded_tw_paths = ['../data/twitter_infos_1_buffer=1.csv', '../data/twitter_infos_2_buffer=1.csv']\n",
    "bounded_fl_paths = ['../data/flickr_photo_in_museum_buffer=1.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smdf_by_buffer(sm_paths):\n",
    "    from collections import defaultdict\n",
    "    dfs = defaultdict(list)\n",
    "    dfs_concat = {}\n",
    "    for path in sm_paths:\n",
    "        bfr = path.rsplit('_',1)[1][:-4]\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        dfs[bfr].append(df)\n",
    "    for bfr, dfs_bfr in dfs.items():\n",
    "        df = pd.concat(dfs_bfr)\n",
    "        dfs_concat[bfr]=df\n",
    "    return dfs_concat\n",
    "dfs_tw = smdf_by_buffer(bounded_tw_paths)\n",
    "dfs_fl = smdf_by_buffer(bounded_fl_paths)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda2\\lib\\site-packages\\dateutil\\parser.py:598: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  elif res.tzname and res.tzname in time.tzname:\n"
     ]
    }
   ],
   "source": [
    "def simplify_sm(dfs_sm, ts_col, keep_cols):\n",
    "    from dateutil.parser import parse as date_parse\n",
    "    def get_yr_mn_dy(x):\n",
    "        dt = date_parse(x)\n",
    "        return '%s_%02d_%02d' %(dt.year, int(dt.month),int(dt.day))\n",
    "    def clean_place(x):\n",
    "        x = x[:-1] if x[-1].isdigit() else x\n",
    "        return x.replace(' ','_')\n",
    "    dfs_sm_simplified = {}\n",
    "    for bfr, df_sm in dfs_sm.items():\n",
    "        df = df_sm.copy()\n",
    "        df['ymd'] = df[ts_col].apply(get_yr_mn_dy)\n",
    "        df['ym'] = df.ymd.apply(lambda x:x[:-3])\n",
    "        df = df[keep_cols].copy()\n",
    "        df.columns = ['smid','user','place', 'ymd','ym']\n",
    "        df.place = df.place.apply(clean_place)\n",
    "        dfs_sm_simplified[bfr]=df\n",
    "    return dfs_sm_simplified\n",
    "\n",
    "dfs_tw = simplify_sm(dfs_tw, 'ts',['smid','user','place','ymd','ym'])\n",
    "dfs_fl = simplify_sm(dfs_fl, 'date_taken', ['id','owner', 'museum', 'ymd','ym'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
